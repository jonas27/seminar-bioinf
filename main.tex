\documentclass[10pt]{article}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{natbib}
\usepackage{graphicx}

\lhead{Luo, Ping, et al.: "deepDriver: predicting cancer driver genes\\ based on somatic mutations using deep convolutional neural networks."\cite{deepdriver}}
\rhead{Jonas Manser\\4953222}

\begin{document}
\vspace*{-6mm}
\section*{Introduction and Motivation}
Cancer is the second leading cause of death in world only behind cardiovascular disease\cite{globalCancerStats}. It is characterized by not well-differentiated cells and abnormal and uncontrolled cellular growth primarily caused by genetic mutations. Cancer driver genes are somatic mutations in tumors expressed more often compared to neutral mutagenesis\footnote{Often with very high inter-tumor variation.} and, thus, thought to be essential in their development and progression.\cite{cancerGenome}.   
% Cancer driver mutations are DNA changes that are causally implicated in oncogenesis

Methods for identifying driver genes are often based on the mutation frequency or network analysis. The former searches for significantly mutated genes (SMG), whereas in the later a gene interaction networks (GIN) is used for predicting driver genes. Past methods often led to flawed identifications and/or very patient specific results. 

Newer research, mostly based on machine learning methods, uses already validated driver genes to predict new ones, predominantly via random forests and SVMs. Both achieve better results than previous methods. In this research the authors use a convolutional neural network (CNN) to exploit spatial information inside a gene similarity network (GSN) to predict cancer driver genes with great avail.  

\section*{Method Description}
% Make it easy but scientific
The researches studied three types of cancer: breast invasive carcinoma (BRCA), colon adenocarcinoma (COAD) and lung adenocarcinoma (LUAD). Their research method has two main components, a GSN and a CNN.  

The mutation and gene expression data comes from the NCI Genomic Data Commons (GDC) with quality controls applied inline with similar research. The GSN is constrcuted by calculating the Peason correlation coefficient (PCC) for each gene $g_i$ compared to all other genes for each of the three cancer types. 
The PCC is used to `characterize the relationships between genes in the disease states'.  
The resulting values are subsequently used in the k-nearest neighbors (kNN) algorithm to construct an undirected network where $k$ genes with the highest PCC are connected. 
For each gene 12 features are constructed and used together with the kNN to construct a 2-D matrix for each gene where the columns represent the genes and the rows their 12 features. 
To gain spatial information the gene in question is repeated for each neighbor, so $k$ times, in the order $g_i, g_s1,g_i,g_s2, ... , g_i,g_sk$. This resulted in a input feature matrix $\phi$ for each gene $g_i$:
\begin{equation}
\phi_i \in R^{2k \times 12}
\end{equation}  

CNNs extrapolate spatial information from the underlying data by combining convolution and pooling layers (usually more than once). To make a classification one or more fully connected (FC) layers are used in the end of the CNN. 
Applying the CNN to a gene input feature matrix $\phi_i$ results in a classification of the gene as a driver gene (or not) for a specific cancer.
For training, this result is then compared to labels collected from two different sources and the error is back-propagated through the network to train the CNN. 
The researches empirically set the size of the filters, the window size of the pooling layers and the stride sizes used in the CONV layers and the pooling layers all to 2. Other hyperparameters (HP), the number of CONV layers (ncl), the number of nodes in the CONV layers (ncn), the number of FC layers (nfl) and the number of nodes in the FC layer (nfn) are optimized with 10-fold cross-validation and grid search. They found that for ncl, ncn, nfl, nfn the optimal values are 2, 24, 1 and 48. Searching for the number of neighbors k, they found 7 was optimal with respect to performance and accuracy.

% where are the known driver genes coming from
\section*{Evaluation and Analysis}
To test their results the author pitted the CNN against an SVM and a random forest algorithm called 20/20+ trained on the same data. They then compared the algorithms results for already known cancer drivers but also for predicting possibly new driver genes, called de novo study.

In all tumors the CNN performed at least 15.1\% better at predicting driver genes for cross-validation and, importantly, outperformed all others in the de novo study. 

Finally, combining similarity networks with CNNs led to remarkable results beating some of the best algorithms today for predicting driver genes for individual cancers. In the future, the authors think a similar approach could be used to predict generic driver genes in pan-cancer data sets. 
\bibliographystyle{plain}
\bibliography{refs}
\end{document}

% https://www.nature.com/articles/s41568-020-0290-x
% https://www.cancercenter.com/what-is-cancer
% https://en.wikipedia.org/wiki/Cancer#Prevention
% https://en.wikipedia.org/wiki/List_of_causes_of_death_by_rate#/media/File:Leading_cause_of_death_world.png
% https://en.wikipedia.org/wiki/Mutagenesis
% Mutagenesis and cell transformation of mammalian cells in culture by chemical carcinogens 
% https://pubmed.ncbi.nlm.nih.gov/722224/
% https://www.cancerquest.org/cancer-biology/cancer-development